{"cells":[{"cell_type":"markdown","source":["# Exercise #1 - Getting Started with PySpark\nIn this exercise you will play with ome basic Spark functions"],"metadata":{}},{"cell_type":"markdown","source":["# Part 1: PySpark Basic"],"metadata":{}},{"cell_type":"markdown","source":["## Python vs PySpark: Map & Reduce\nThe code below creates a list of numbers, multiplies each number by itself and sums their result.\nWe will see an example with Python and another one with PySpark so you can see the differences:Â®"],"metadata":{}},{"cell_type":"code","source":["from operator import add\nl = [1,2,3,4,5]"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Python Example\nfrom functools import reduce\n\nreduce(add, map(lambda i: i*i, l))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# PySpark example\nsc.parallelize(l)\\\n  .map(lambda i: i*i)\\\n  .reduce(add)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Task 1 - Read a file\nFor your first task you'll need to do the following:\n1. Upload the `wordcount.txt` file to DBFS\n2. Read it with spark (Hint: the path is `/FileStore/tables/wordcount.txt`)\n3. Print the first three lines"],"metadata":{}},{"cell_type":"code","source":["# Write your code here\nrdd = sc.textFile(\"/FileStore/tables/wordcount.txt\")\nrdd.take(3)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Task 2 - Filter & Count\n1. Count how many lines does the RDD have\n2. Filter the text so it only contains lines with the word 'Hadoop' (case insensitive).\n2. Count now how many lines are in the rdd after filtering it"],"metadata":{}},{"cell_type":"code","source":["# Write your code here\nprint(\"Lines before filtering: {}\".format(rdd.count()))\nrdd_filtered = rdd.filter(lambda line: 'hadoop' in line.lower())\nprint(\"Lines after filtering: {}\".format(rdd_filtered.count()))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## Task 3 - Word Count\n1. Write a word count application using the same input of task 1 (not the filtered rdd)\n2. Print the results (Word -> Count)\n3. Sort the output in descending order (the word that appears the most will be in the beginning) and print the top 20 words with their counter"],"metadata":{}},{"cell_type":"code","source":["# Write your code here\nfrom operator import add\nword_count = rdd\\\n              .flatMap(lambda line: line.split(\" \"))\\\n              .map(lambda word: (word, 1))\\\n              .reduceByKey(add)\\\n              .collect()\n# .reduceByKey(add) is similar to .reduceByKey(lambda a,b: a+b)\nprint(\"Word count output: {}\\n\".format(word_count))\n\nsorted_words = sorted(word_count, key=lambda x: x[1], reverse=True)\ntop_20_words = sorted_words[:20]\nprint(\"The top 20 words are: {}\".format(top_20_words))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Task 4 - Factorial\n1. Write a Spark application that receives a number N and returns factorial of N (N!). You can assume that N > 0.\n\n\n\n#### Definition of factorial\nIn mathematics, the factorial of a positive integer n, denoted by n!, is the product of all positive integers less than or equal to n:\n\n`n! = n x (n-1) x (n-2) x ... x 3 x 2 x 1`\n\nFor example:\n\n`5! = 5 x 4 x 3 x 2 x 1`\n\nThe value of 0! is 1."],"metadata":{}},{"cell_type":"code","source":["N = 5 # Replace N with a small number to test the code\nrdd = sc.parallelize(range(1, N+1))\n\n# Write your code here\nrdd.reduce(lambda a,b: a*b)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["## Task 5 - Modulo\n1. Write a Spark application that receives natural numbers X1 and X2, such that `X2 > X1 > 0`, and returns all the numbers between X1 and X2 that can be divided by 3 `x%3 == 0`.\n2. Same as the step before but receive Y1, Y2 and return all the numbers between Y1 and Y2 that can be divided by 4.\n3. Create and RDD that contains both rdds from step 1 and 2, without duplicates and sorted from lowest to highest.\n4. Print the sorted RDD from step 3."],"metadata":{}},{"cell_type":"code","source":["X1 = 1\nX2 = 50\nrddX = sc.parallelize(range(X1,X2))\n\nY1 = 1\nY2 = 50\nrddY = sc.parallelize(range(Y1,Y2))\n\n# 1. Write your code here\nrddX = rddX.filter(lambda x: x%3 == 0)\n\n# 2. Write your code here\nrddY = rddY.filter(lambda y: y%4 == 0)\n\n# 3. Write your code here\nrdd = sc.union([rddX, rddY]).distinct().sortBy(lambda x: x)\n\n# 4. Write your code here\nrdd.collect()"],"metadata":{},"outputs":[],"execution_count":16}],"metadata":{"name":"01_Spark_GettingStarted_solution","notebookId":486218037067121},"nbformat":4,"nbformat_minor":0}
