{"cells":[{"cell_type":"markdown","source":["#Exercise #3 - Movies Exercises\nBecause you loved doing movies-related exeercises with MapReduce and Spark, we will continue the tradition, this time with SparkSQL =D"],"metadata":{}},{"cell_type":"markdown","source":["## Task 1 - Find the movies with the lowest average rating\nIn this task, you'll have answer the question: **\"What are the 10 worst movies in the MovieLens dataset?\"**\n\nWe're going to define the \"worst movies\" as the ones with **lowest average rating** and with **at least 10 users that rated it**.\n\nUse the `FileStore/tables/ratings.csv` file to complete this task."],"metadata":{}},{"cell_type":"code","source":["# Write your code here\nfrom pyspark.sql import functions as F"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Task 2 - Find the movie names with the best average rating\nThis task is similar to task #2, with two main differences:\n1. This time we want the top 10 movies (with the highest ratings and at least 10 user rates)\n2. We want the name of the movies and it's average rating, not it's ID. Hint: You'll have to join the result with the `movies` dataset in: `/FileStore/tables/ratings.csv`."],"metadata":{}},{"cell_type":"code","source":["# Write your code here\nfrom pyspark.sql import functions as F"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["## Task #3 - Movies Genre\nIn this task we are also going to use both the `ratings.csv` and `movies.csv` dataset to answer the following questions:\n\n1. What are all the different genres of the movies?\n2. How many movies are in each genre? Show it in a 'Pie' graph in databricks.\n3. What's the average rating given for each genre? \n\n#### Hints\n1. You can convert DFs to RDDs and the opposite to make the job easier.\n2. After reading the datasets into the DF, convert it into an RDD to extract the genres with the help of a map function, convert the result back into a DF with the genre column as an Array.\n3. Don't forget about the `explode` methos in SparkSQL you might find it usefull.\n4. You can create an DF from an RDD with the help of the method `rdd.toDF()` and the object `Row` from `pyspark.sql`."],"metadata":{}},{"cell_type":"code","source":["# Write your code here\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Row"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["## Task 4 - Years Analysis\nIn this task we are also going to use both the `ratings.csv` and `movies.csv` dataset to answer the following questions:\n\n1. How many movies where there in each year? Sort them in descending order and display a 'Bar' graph with databricks\n2. Which year has the best average rating? Only count years with more than 10 ratings"],"metadata":{}},{"cell_type":"code","source":["# Write your code here\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Row"],"metadata":{},"outputs":[],"execution_count":9}],"metadata":{"name":"03_SparkSQL_MoviesExercises","notebookId":3161721424282851},"nbformat":4,"nbformat_minor":0}
