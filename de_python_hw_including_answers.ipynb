{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "de_python_hw_including_answers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSJSGWXY58FXO171XT7j11",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagi15G/de_python_course/blob/main/de_python_hw_including_answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KVb993uJeKv"
      },
      "source": [
        "# DE Python Home Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1679f0zJwVi"
      },
      "source": [
        "## Part 1 : Data Loading\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF2-NtwiJ-kp"
      },
      "source": [
        "Our data set for this assignment is around the [ATP tour](https://en.wikipedia.org/wiki/ATP_Tour)\n",
        "\n",
        "The CSV files we will work with are:\n",
        "\n",
        "Rankings:\n",
        "\n",
        "1. https://raw.githubusercontent.com/Sagi15G/de_python_course/main/data/atp_csv/atp_rankings_90s.csv\n",
        "2. https://raw.githubusercontent.com/Sagi15G/de_python_course/main/data/atp_csv/atp_rankings_00s.csv\n",
        "3. https://raw.githubusercontent.com/Sagi15G/de_python_course/main/data/atp_csv/atp_rankings_current.csv\n",
        "\n",
        "Players:\n",
        "\n",
        "1. https://raw.githubusercontent.com/Sagi15G/de_python_course/main/data/atp_csv/atp_players.csv\n",
        "\n",
        "\n",
        "**TO DO:**\n",
        "\n",
        "Click the links and write to your self some \"metadata\" about the files.\n",
        "\n",
        "For example:\n",
        "- Does the file contains header?\n",
        "- Does the file is comma seperated?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIX-f-uLDEjq"
      },
      "source": [
        "# make sure to import pandas (:\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqYLHiSaMhwd"
      },
      "source": [
        "###Task 1:\n",
        "\n",
        "Create a dataframe for all the rankings data\n",
        "\n",
        "- The name of the dataframe should be **df_rankings**\n",
        "- The columns should be: **ranking_date,rank,player,points**\n",
        "- Hint: You can use the [concat function](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) to concatinate the multiple dataframes into a single dataframe \n",
        "- [pandas.read_csv documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX332drcDH-2"
      },
      "source": [
        "\"\"\" \n",
        "Task 1- Write Your Code Here \n",
        "Output:  a dataframe named df_rankings\n",
        "\"\"\"\n",
        "\n",
        "# key=path, value=is_contains_header\n",
        "data_sources = {\"https://raw.githubusercontent.com/Sagi15G/de_python_course/main/data/atp_csv/atp_rankings_90s.csv\":1,\n",
        "                \"https://raw.githubusercontent.com/Sagi15G/de_python_course/main/data/atp_csv/atp_rankings_00s.csv\":1,\n",
        "                \"https://raw.githubusercontent.com/Sagi15G/de_python_course/main/data/atp_csv/atp_rankings_current.csv\":0}\n",
        "\n",
        "list_of_df = []\n",
        "\n",
        "\n",
        "for k,v in data_sources.items():\n",
        "  list_of_df.append(pd.read_csv(filepath_or_buffer=k,skiprows=v,names=['ranking_date','rank','player','points']))\n",
        "\n",
        "df_rankings = pd.concat(list_of_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrkHjW0COT-T"
      },
      "source": [
        "\"\"\"\n",
        "Task 1: Auto-QA \n",
        "Make sure you can run this cell without errors\n",
        "\"\"\"\n",
        "NUM_OF_RECORDS = 1672885\n",
        "assert len(df_rankings)==NUM_OF_RECORDS,\"The number of records in the df_rankings Dataframe should be {0} and not {1}\".format(NUM_OF_RECORDS,len(df_rankings))\n",
        "\n",
        "\n",
        "for c in ['ranking_date','rank','player','points']:\n",
        "  assert c in df_rankings.columns.values.tolist(),\"The column {0} is not exists in the dataframe df_rankings\".format(c)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3UNQksrazhP"
      },
      "source": [
        "###Task 2:\n",
        "\n",
        "Create a dataframe for the players data\n",
        "\n",
        "- The name of the dataframe should be **df_players**\n",
        "- The columns should be: **player_id, first_name, last_name, hand, birth_date, country_code**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev9m6qEzbPyC"
      },
      "source": [
        "\"\"\" \n",
        "Task 2- Write Your Code Here \n",
        "\n",
        "Output: a dataframe named df_players\n",
        "\"\"\"\n",
        "df_players = pd.read_csv(filepath_or_buffer='https://raw.githubusercontent.com/Sagi15G/de_python_course/main/data/atp_csv/atp_players.csv'\n",
        "              ,skiprows=0,names=['player_id', 'first_name', 'last_name', 'hand', 'birth_date', 'country_code'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOAM7JaHbrTl"
      },
      "source": [
        "\"\"\"\n",
        "Task 2: Auto-QA \n",
        "Make sure you can run this cell without errors\n",
        "\"\"\"\n",
        "NUM_OF_RECORDS = 55048\n",
        "assert len(df_players)==NUM_OF_RECORDS,\"The number of records in the df_players Dataframe should be {0} and not {1}\".format(NUM_OF_RECORDS,len(df_players))\n",
        "\n",
        "\n",
        "for c in ['player_id', 'first_name', 'last_name', 'hand', 'birth_date', 'country_code']:\n",
        "  assert c in df_players.columns.values.tolist(),\"The column {0} is not exists in the dataframe df_players\".format(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "img-rbSiebHX"
      },
      "source": [
        "## Part 2 : Data Exploration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU3Jot20eEQi"
      },
      "source": [
        "###Task 3:\n",
        "\n",
        "Unserstand the data of **df_rankings**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_BRfFqkeOxw"
      },
      "source": [
        "\"\"\" \n",
        "Task 3.1- Write Your Code Here \n",
        "Do we have any columns that contains nulls?\n",
        "\n",
        "Output: a print that answers the question\n",
        "\n",
        "Hint: you can answer this question in a single command (check the class notebook)\n",
        "\"\"\"\n",
        "df_rankings.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQBW6ICjfQkm"
      },
      "source": [
        "\"\"\" \n",
        "Task 3.2- Write Your Code Here \n",
        "Add a new column to the rankings dataframe named ranking_date_as_datetime\n",
        "The new column data type should be datetime64[ns] when running df_rankings.dtypes\n",
        "\n",
        "Output: a new column named ranking_date_as_datetime\n",
        "\n",
        "Hint: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
        "\"\"\"\n",
        "df_rankings['ranking_date_as_datetime'] = pd.to_datetime(df_rankings['ranking_date'] ,format='%Y%m%d')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmYeRfxmg6UG"
      },
      "source": [
        "\"\"\"\n",
        "Task 3.2: Auto-QA \n",
        "Make sure you can run this cell without errors\n",
        "\"\"\"\n",
        "assert df_rankings['ranking_date_as_datetime'].dtypes =='datetime64[ns]',\"The column ranking_date_as_datetime does not exists or created with a wrong type\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B92CWBS3iOtg"
      },
      "source": [
        "list_of_missing_months = []\n",
        "\n",
        "\"\"\" \n",
        "Task 3.3- Write Your Code Here \n",
        "Do we have any holes in the data in terms of missing months?\n",
        "Explanation: if our data date range is between the  January/2000 and April/2001,we excpect to see at least one row from each month in the range (12+4= 16 months)\n",
        "\n",
        "\n",
        "Output: Fill the list \"list_of_missing_months\" with missing months as string in the format of YYYY-MM\n",
        "For example, if we have holes in January/1991 and April/1992 then list_of_missing_months should be equals to ['1991-01','1992-04']\n",
        "\"\"\"\n",
        "min_date = df_rankings.ranking_date_as_datetime.min()\n",
        "max_date = df_rankings.ranking_date_as_datetime.max()\n",
        "\n",
        "\n",
        "all_months = []\n",
        "\n",
        "for y in range(min_date.year,max_date.year+1):\n",
        "  for m in range(1,13):\n",
        "    # Lower bound check\n",
        "    if y==min_date.year and m<min_date.month:\n",
        "      # ignore these months\n",
        "      pass \n",
        "    # Upper bound check\n",
        "    elif y==max_date.year and m>max_date.month:\n",
        "       # ignore these months\n",
        "      pass\n",
        "    else :\n",
        "      all_months.append('{year}-{month}'.format(month=m if m >=10 else \"0{0}\".format(m),year=y))\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "_df_months=df_rankings['ranking_date_as_datetime'].dt.strftime(\"%Y-%m\").unique().tolist()\n",
        "list_of_missing_months=list(set(all_months)- set(_df_months))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcs4EIv14cJR"
      },
      "source": [
        "\"\"\"\n",
        "Task 3.3: Auto-QA \n",
        "Make sure you can run this cell without errors\n",
        "\"\"\"\n",
        "assert len(list_of_missing_months) == 132,\"Wrong answer\"\n",
        "\n",
        "# Can you think of the reason why we have these holes? hint: check the data sets names\n",
        "print(list_of_missing_months)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_xULqCE6jHD"
      },
      "source": [
        "\"\"\" \n",
        "Task 3.4- Write Your Code Here \n",
        "Delete from the data frame df_rankings all the data of 2021\n",
        "\n",
        "\n",
        "Output: The dataframe shoule not contain data of 2021\n",
        "\"\"\"\n",
        "# <=2009 will work as well\n",
        "df_rankings = df_rankings.loc[df_rankings[\"ranking_date_as_datetime\"].dt.year <= 2020]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULmOs2LJ55Ia"
      },
      "source": [
        "\"\"\"\n",
        "Task 3.4: Auto-QA \n",
        "Make sure you can run this cell without errors\n",
        "\"\"\"\n",
        "\n",
        "assert df_rankings.ranking_date_as_datetime.dt.year.max()==2009\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2Ec8haD7gew"
      },
      "source": [
        "###Task 4:\n",
        "\n",
        "Unserstand the data of **df_players**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aar6wzuN7bFA"
      },
      "source": [
        "\"\"\" \n",
        "Task 4.1- Write Your Code Here \n",
        "Verify that player_id is unique (primary key) for the dataset df_players\n",
        "\n",
        "output: any output that proves it\n",
        "\"\"\"\n",
        "assert len(df_players.player_id.value_counts())==len(df_players)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjq3k1wS8n6w"
      },
      "source": [
        "\"\"\" \n",
        "Task 4.1- Write Your Code Here \n",
        "Check if we have players in df_rankings which not exists in  df_players\n",
        "\n",
        "\n",
        "output: output that shows the answer\n",
        "Hint: try to Google about translating this SQL code to pandas:\n",
        "SELECT *\n",
        "FROM df_rankings R LEFT JOIN df_players P\n",
        "  ON R.player=P.player_id\n",
        "WHERE P.player_id IS NULL\n",
        "\"\"\"\n",
        "_df = pd.merge(df_rankings, df_players, left_on=['player'], right_on=['player_id'], how=\"left\", indicator=True)\n",
        "_df[_df['_merge'] == 'left_only']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}