{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pandas_transform_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM2Or5sY65x0PZ+wo8JobF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagi15G/de_python_course/blob/main/pandas_transform_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMlpg2EMdHqY"
      },
      "source": [
        "# Transform your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9784aICb4kkR"
      },
      "source": [
        "This session assumes you went over the pandas lessons in Kaggle: link: https://www.kaggle.com/learn/pandas\n",
        "* lesson 1: Creating, Reading and Writing: https://www.kaggle.com/residentmario/creating-reading-and-writing\n",
        "* lesson 2: Indexing, Selecting & Assigning: https://www.kaggle.com/residentmario/indexing-selecting-assigning \n",
        "* lesson 3: Summary Functions and Maps: https://www.kaggle.com/residentmario/summary-functions-and-maps\n",
        "* lesson 4: Grouping and Sorting: https://www.kaggle.com/residentmario/grouping-and-sorting\n",
        "* lesson 5: Data Types and Missing Values: https://www.kaggle.com/residentmario/data-types-and-missing-values\n",
        "* lesson 6: Renaming and Combining: https://www.kaggle.com/residentmario/renaming-and-combining "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlxNo4YaajzF"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pH5-45xfnp2"
      },
      "source": [
        "## Basic Skills\n",
        "Before we start, let's go over some important pandas skills we'll be using:\n",
        "\n",
        "- Sorting\n",
        "- Dropping missing values\n",
        "- Checking for duplicates\n",
        "- Joining\n",
        "- Group by\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCcOosYJghqY"
      },
      "source": [
        "# Define a sample dataframe:\n",
        "\n",
        "list_of_lists = [\n",
        "    ['Tom', 10, 'Tel Aviv'], \n",
        "    ['Jerry', 15, 'Tel Aviv'], \n",
        "    ['Ben', 21, 'Nahariyya'],\n",
        "    ['Jerry', 22, 'Nahariyya'],\n",
        "    ['Michal', 25, 'Eilat'],\n",
        "    ['Maya'],\n",
        "    ['Maya', 3],\n",
        "]\n",
        "  \n",
        "# Create the pandas DataFrame\n",
        "df = pd.DataFrame(list_of_lists, columns = ['Name', 'Age', 'City'])\n",
        "\n",
        "# Look at a sample of the data\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwbD-bTt5WwT"
      },
      "source": [
        "###**Sorting**\n",
        "\n",
        "Documentation: \n",
        "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\n",
        "* https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9WmiB5yf9SK"
      },
      "source": [
        "# Sorting by a numeric column\n",
        "df = df.sort_values(by=['Age'])\n",
        "print(\"Sorting by age:\")\n",
        "print(df, \"\\n\")\n",
        "\n",
        "# Sorting by a numeric column: high to low\n",
        "df = df.sort_values(by=['Age'], ascending=False)\n",
        "print(\"Sorting by age: high to low\")\n",
        "print(df, \"\\n\")\n",
        "\n",
        "# Sorting by a textual column\n",
        "df = df.sort_values(by=['Name'])\n",
        "print(\"Sorting by name:\")\n",
        "print(df, \"\\n\")\n",
        "\n",
        "# Sort by index column\n",
        "df = df.sort_index()\n",
        "print(\"Sorting by index:\")\n",
        "print(df, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxZTgCA16S2L"
      },
      "source": [
        "###**Drop missing values**\n",
        "* Documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K04g2Dl4gWLD"
      },
      "source": [
        "# Show nulls\n",
        "df_v1 = df.isna()\n",
        "print(\"Is this value missing from the df?\")\n",
        "print(df_v1, \"\\n\")\n",
        "\n",
        "# Drop all missing values\n",
        "# We had missing age and city values, all were dropped\n",
        "df_v2 = df.dropna()\n",
        "print(\"Drop all missing values\")\n",
        "print(df_v2, \"\\n\")\n",
        "\n",
        "# Drop missing from specific column\n",
        "df_v3 = df.dropna(subset=['Age'])\n",
        "print(\"Drop missing ages only\")\n",
        "print(df_v3, \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYzts1WA7KDs"
      },
      "source": [
        "###**Check for duplicate values**\n",
        "* Documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjlK24HYf9tD"
      },
      "source": [
        "# Do we have duplicated rows? (single answer)\n",
        "print(\"Do we have duplicate rows? (returning a single answer)\")\n",
        "boolean_answer = df.duplicated().any()\n",
        "print(boolean_answer, \"\\n\")\n",
        "\n",
        "# Do we have duplicated rows? (answer per row)\n",
        "print(\"Do we have duplicate rows? (Return a series specifying if a row is a duplicate)\")\n",
        "df_v1 = df.duplicated()\n",
        "print(df_v1, \"\\n\")\n",
        "\n",
        "# Do we have duplicated values in a specific column? (column: Name)\n",
        "print(\"Do we have duplicated values in the 'Name' column?\")\n",
        "boolean_answer = df.Name.duplicated().any()\n",
        "print(boolean_answer, \"\\n\")\n",
        "\n",
        "# What duplicate values does the column \"Name\" have?\n",
        "print(\"What are the duplicated values?\")\n",
        "print(df.Name[df.Name.duplicated()], \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJB7yKKH8ANs"
      },
      "source": [
        "###**Join**\n",
        "* Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ_7eHwq0Gxo"
      },
      "source": [
        "# Let's define an additional dataframe\n",
        "\n",
        "cities = [\n",
        "    ['Nahariyya', 'North', 58000], \n",
        "    ['Tel Aviv-Yafo', 'Center', 435900], \n",
        "    ['Beer Sheva', 'South', 205000], \n",
        "    ['Eilat', 'South', 52000],\n",
        "]\n",
        "  \n",
        "# Create the pandas DataFrame\n",
        "df2 = pd.DataFrame(cities, columns = ['City', 'Area', 'Population'])\n",
        "\n",
        "# Look at a sample of the data\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le_K9uGzf9kG"
      },
      "source": [
        "# Join each person in df with info about the city where they live\n",
        "\n",
        "# Inner Join \n",
        "print(\"Inner join: return only rows that exist in both datasets\")\n",
        "print(df.join(df2.set_index('City'), on='City',  how='inner'), \"\\n\")\n",
        "\n",
        "# Left Join \n",
        "print(\"Left join: return all rows that exist in df, and rows in df2 if they match\")\n",
        "print(df.join(df2.set_index('City'), on='City',  how='left'), \"\\n\")\n",
        "\n",
        "# Full Outer Join \n",
        "print(\"Outer join: rows that exist in either dataset\")\n",
        "print(df.join(df2.set_index('City'), on='City',  how='outer'), \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onw1piPm8rEJ"
      },
      "source": [
        "###**Group by**\n",
        "* Documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkAuKTvVf91V"
      },
      "source": [
        "# How many people live in a city with a population of > 55K?\n",
        "\n",
        "# 1. Let's edit df2's city names to align with df1\n",
        "print(\"Changing city name to enable matching between datasets:\")\n",
        "df2.City.iloc[1] = 'Tel Aviv'\n",
        "print(df2, \"\\n\")\n",
        "\n",
        "# 2.Left join between the datasets\n",
        "print(\"Left join df with df2\")\n",
        "df3 = df.join(df2.set_index('City'), on='City',  how='left') \n",
        "print(df3, \"\\n\")\n",
        "\n",
        "#3. Keep rows with population > 55K in dataset\n",
        "print(\"Keep values with population > 55K\")\n",
        "df3 = df3[df3['Population'] > 55000]\n",
        "print(df3, \"\\n\")\n",
        "\n",
        "\n",
        "# 3. Group by city and count results\n",
        "print(\"Group by 'City' and count results\")\n",
        "df3 = df3.groupby(['City']).size()\n",
        "print(df3, \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aflh_50O9bZX"
      },
      "source": [
        "## Transforming The Movie Datasets\n",
        "\n",
        "In the following lesson, we'll use pandas to transform the movies dataset we explored last lesson into a more usable version.\n",
        "\n",
        "We'll focus on several skills:\n",
        "* Cleanig our data\n",
        "* Asking questions about the data\n",
        "* Changing the data to support analysis\n",
        "* Using the data to answer our questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBJMGC1D-OJy"
      },
      "source": [
        "**Loading the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO0biYo5ZZUm"
      },
      "source": [
        "last lesson, we loaded each csv into a separate df and examined it. This time let's be more organized by creating one dictionary to store all the different dataframes.\n",
        "\n",
        "dataframes is a dictionary:\n",
        "* dataframes['movies'] will contain movies.csv\n",
        "* dataframes['ratings'] will contain ratings.csv \n",
        "and so on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi1j2dsNWTvm"
      },
      "source": [
        "# using \"!\" on this notebook will run a bash command\n",
        "! git clone https://github.com/Sagi15G/de_python_course.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkZG2QGSY9JY"
      },
      "source": [
        "# define a single dictionary to store all the datasets\n",
        "dataframes = {}\n",
        "\n",
        "# load each of the datasets into the dictionary\n",
        "for csv_name in ['ratings', 'tags', 'movies', 'links']:\n",
        "  dataframes['{}'.format(csv_name)] = pd.read_csv(filepath_or_buffer='de_python_course/data/movies_csv/{}.csv'.format(csv_name),sep=',')\n",
        "\n",
        "# example for accessing a single df:\n",
        "dataframes['movies'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlzSbGuuc_7l"
      },
      "source": [
        "### Step 1: Cleaning up the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htb5n221dUTd"
      },
      "source": [
        "We want to clean up the 'movies' data so it will be easier to use later on in our analysis. In order to do this, let's look at the data and imagine edge cases it may have. Let's frame these edge cases as questions and answer them. \n",
        "\n",
        "Some examples:\n",
        "* Do we have missing titles? genres?\n",
        "* Do we have upper/lower case issues with titles?\n",
        "* Can we have multiple rows for a single movie title?\n",
        "* Is each movie id unique?\n",
        "* Do all movies have year information?\n",
        "* Do all years make sense?\n",
        "* Do we have the same movie names for different years?\n",
        "\n",
        "Do you have additional questions you want to ask?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxxNfYBdZJ1D"
      },
      "source": [
        "####**Do we have missing titles/genres?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbcpJPCoRGfQ"
      },
      "source": [
        "# do we have missing values\n",
        "print(\"Are 'title' values missing?\")\n",
        "print(dataframes['movies'].title.isna().any())\n",
        "\n",
        "print(\"Are 'genre' values missing?\")\n",
        "print(dataframes['movies'].genres.isna().any())\n",
        "\n",
        "# Can genre values have blank spaces?\n",
        "print(\"Are there 'genre' values with blank spaces?\")\n",
        "dataframes['movies'][dataframes['movies']['genres'].str.contains(\" \")].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT9ruDn5YTMG"
      },
      "source": [
        "# Let's rename the missing genres as an 'unknown' genre using a lambda function\n",
        "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
        "\n",
        "dataframes['movies']['genres'] = dataframes['movies']['genres'].apply(lambda x: x if x != \"(no genres listed)\" else \"unknown\")\n",
        "\n",
        "dataframes['movies'][dataframes['movies']['genres'].str.contains(\"unknown\")].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NctwTZ7n9DY"
      },
      "source": [
        "####**Do we have upper/lower case issues with titles?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY-djH_CoUUK"
      },
      "source": [
        "# Our titles are case sensitive - let's change that!\n",
        "dataframes['movies']['title'] = dataframes['movies']['title'].str.lower()\n",
        "\n",
        "dataframes['movies'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuDhPJMBZQGq"
      },
      "source": [
        "####**Do we have duplicate rows for a movie title?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wkD3R3LcEnk"
      },
      "source": [
        "# Do we have duplicate rows for a movie title?\n",
        "print(\"Is there a movie title with more than one row?\")\n",
        "dataframes['movies'].title.duplicated().any()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVwBPE2ybE4i"
      },
      "source": [
        "# Which rows have duplicated titles?\n",
        "dataframes['movies'].title.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg6gLGukbNrC"
      },
      "source": [
        "# Let's return dataframe rows where we have duplicated titles:\n",
        "\n",
        "titles = dataframes['movies']['title']\n",
        "duplicates = dataframes['movies'][titles.isin(titles[titles.duplicated()])]\n",
        "duplicates.sort_values(by=[\"title\"])\n",
        "\n",
        "# The difference seems to be the number of genres!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOdybV30lVT_"
      },
      "source": [
        "# Keep one row per duplicated title\n",
        "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html\n",
        "\n",
        "# Keep only one row for each duplicated value using drop_duplicates\n",
        "dataframes['movies'] = dataframes['movies'].drop_duplicates(subset=['title'], keep='last')\n",
        "\n",
        "print(\"Is there a movie title with more than one row now?\")\n",
        "dataframes['movies'].title.duplicated().any()\n",
        "\n",
        "# Ideally, we'd do something smarter, like keep the rows with more genre information. You can try it yourself..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgTgdaiDs5Rw"
      },
      "source": [
        "####**Is each movie id unique?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peyJ1IpBs_eC"
      },
      "source": [
        "# Is each movie id unique?\n",
        "dataframes['movies']['movieId'].value_counts().max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRO41v-1qLSh"
      },
      "source": [
        "####**Do all movies have year information?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPX11LHYnV-1"
      },
      "source": [
        "# we'll add the 'has_year' column with True/False values based on the title string\n",
        "dataframes['movies']['has_year'] = dataframes['movies']['title'].apply(lambda x: x.split()[-1].strip(\"()\").isnumeric())\n",
        "\n",
        "# movies that don't have year information\n",
        "dataframes['movies'][~dataframes['movies']['has_year']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtigEuGgtaGo"
      },
      "source": [
        "####**Do all years make sense?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5rjmR3-ktSU"
      },
      "source": [
        "# Let's add a year column to the dataset \n",
        "\n",
        "# Create a year column assuming title format is: <some string> (year)\n",
        "# If the year string is available, use it, otherwise set year = -1\n",
        "dataframes['movies']['year'] = dataframes['movies'][['title','has_year']].apply(lambda x: int(x[0].split()[-1].strip(\"()\")) if x[1] else -1,  axis=1)\n",
        "\n",
        "# Sample results:\n",
        "dataframes['movies'][dataframes['movies']['has_year']].head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YDnUyCetkSr"
      },
      "source": [
        "# what's the minimal year?\n",
        "has_year = dataframes['movies'][dataframes['movies']['has_year']]\n",
        "has_year.sort_values(by=['year']).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtHSNjStvG-9"
      },
      "source": [
        "# update the year calculation to only use 4-digit years\n",
        "def title_contains_year(x):\n",
        "  year_string = x.split()[-1].strip(\"()\")\n",
        "  return year_string.isnumeric() and len(year_string) == 4\n",
        "\n",
        "# recalculate has_year and year\n",
        "dataframes['movies']['has_year'] = dataframes['movies']['title'].apply(lambda x: title_contains_year(x))\n",
        "dataframes['movies']['year'] = dataframes['movies'][['title','has_year']].apply(lambda x: int(x[0].split()[-1].strip(\"()\")) if x[1] else -1,  axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6HY4wWOtklG"
      },
      "source": [
        "# what's the minimal year now?\n",
        "has_year = dataframes['movies'][dataframes['movies']['has_year']]\n",
        "has_year.sort_values(by=['year']).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUv07dp2zxp-"
      },
      "source": [
        "### Step 2: Asking questions about the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIC98BCW2lDc"
      },
      "source": [
        "* Do we have movies with foreign titles?\n",
        "* Can one movie appear with multiple years in our data?\n",
        "* What is the average rating per movie title?\n",
        "* Do recent movies have more ratings on avg than older movies?\n",
        "* Does positive/negative sentiment towards a movie in the 'tags' dataset translate to high/low average rating?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kpsu5EX4AJS"
      },
      "source": [
        "### Steps 3+4: Changing the data to support analysis & Using the data to answer our questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxqpuCrc4tn5"
      },
      "source": [
        "####**Do we have movies with foreign titles?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mrgY0TrnTtG"
      },
      "source": [
        "# Do we have movies in other languages?\n",
        "# Documentation: https://docs.python.org/3/library/stdtypes.html\n",
        "\n",
        "# Define a function checking whether all values \n",
        "def isEnglish(s):\n",
        "    return s.isascii()\n",
        "\n",
        "# Define is_english column by applying the function to each tite\n",
        "dataframes['movies']['is_english'] = dataframes['movies']['title'].apply(lambda x: isEnglish(x))\n",
        "\n",
        "# Display a sample of the results\n",
        "print(\"Non-english titles:\")\n",
        "dataframes['movies'][~dataframes['movies']['is_english']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4pRtpFI5CE4"
      },
      "source": [
        "####**Can one movie appear with multiple years in our data?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZM7NuVYuPnV"
      },
      "source": [
        "# Create a new column containing the title name with no year\n",
        "dataframes['movies']['movie_name'] = dataframes['movies'][['title','has_year']].apply(lambda x: \" \".join(x[0].split()[:-1]) if x[1] else x[0],  axis=1)\n",
        "\n",
        "# Sample results:\n",
        "dataframes['movies'][dataframes['movies']['has_year']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t2EvRkx3IIB"
      },
      "source": [
        "# do we have the same movie names for different years?\n",
        "\n",
        "movie_names = dataframes['movies'].groupby(['movie_name']).size() \n",
        "movie_names.loc[movie_names.values>1].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLPwKP6D6Bho"
      },
      "source": [
        "# let's look at an example from the dataset:\n",
        "dataframes['movies'][dataframes['movies']['movie_name'] == 'hamlet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uDiXr2JnRwn"
      },
      "source": [
        "####**What is the average rating per movie title?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f21MEtyf6Uwx"
      },
      "source": [
        "# We'll finally use the ratings dataset! \n",
        "# Let's validate all rows have ratings\n",
        "print(\"Are there rows with missing ratings?\")\n",
        "dataframes['ratings']['rating'].isna().any()\n",
        "\n",
        "print(\"What is the min rating in the dataset?\")\n",
        "dataframes['ratings']['rating'].min()\n",
        "\n",
        "print(\"What is the max rating in the dataset?\")\n",
        "dataframes['ratings']['rating'].max()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2DjRIPbDPpk"
      },
      "source": [
        "# get avg rating per movie\n",
        "print(\"Get mean rating per movie\")\n",
        "mean_rating = dataframes['ratings'][['movieId', 'rating']].groupby(['movieId']).mean()\n",
        "print(mean_rating.head(), \"\\n\")\n",
        "\n",
        "# round avg rating to nearest 0.1 value\n",
        "# Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html\n",
        "print(\"Rounding to nearest 0.1 value\")\n",
        "mean_rating = mean_rating.round(decimals=1)\n",
        "print(mean_rating.head(), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHzIYye8G2ud"
      },
      "source": [
        "# Match each movie with the avg rating and store in a new dataset\n",
        "\n",
        "# Left Join (add 'rating' to 'movies' df)\n",
        "dataframes['combined'] = dataframes['movies'].join(mean_rating, on='movieId',  how='left')\n",
        "\n",
        "# Rename the 'rating' column to 'mean_rating'\n",
        "dataframes['combined'] = dataframes['combined'].rename(columns={'rating':'mean_rating'})\n",
        "\n",
        "# Display a sample of the data\n",
        "dataframes['combined'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg0oUTz8UuI"
      },
      "source": [
        "####**Do recent movies have more ratings on avg than older movies?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXvlTITM6U0R"
      },
      "source": [
        "# Get number of ratings per movie\n",
        "print(\"Get number of ratings per movie\")\n",
        "num_ratings = dataframes['ratings'][['movieId', 'rating']].groupby(['movieId']).size()\n",
        "num_ratings = num_ratings.to_frame('num_ratings')\n",
        "num_ratings.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lJ0o5_j8z5f"
      },
      "source": [
        "# Match each movie with the number of ratings it had\n",
        "\n",
        "# Left Join to add number of ratings to 'movies' df\n",
        "dataframes['combined'] = dataframes['combined'].join(num_ratings, on='movieId',  how='left')\n",
        "\n",
        "# Display a sample of the data\n",
        "dataframes['combined'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cQIlJNh9Yrl"
      },
      "source": [
        "# define movie year buckets\n",
        "\n",
        "def year_bucket(year):\n",
        "  if year == -1:\n",
        "    return 'unknown_year'\n",
        "  elif year < 1960:\n",
        "    return '1960-'\n",
        "  elif year >= 1960 and year < 1970:\n",
        "    return '1960-1970'\n",
        "  elif year >= 1970 and year < 1980:\n",
        "    return '1970-1980'\n",
        "  elif year >= 1980 and year < 1990:\n",
        "    return '1980-1990'\n",
        "  elif year >= 1990 and year < 2000:\n",
        "    return '1990-2000'\n",
        "  elif year >= 2000 and year < 2010:\n",
        "    return '2000-2010'\n",
        "  else:\n",
        "    return '2010+'\n",
        "\n",
        "dataframes['combined']['year_bucket'] = dataframes['combined']['year'].apply(lambda x: year_bucket(x))\n",
        "dataframes['combined'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DF2eeTI_MGn"
      },
      "source": [
        "dataframes['combined'][['year_bucket', 'num_ratings']].groupby('year_bucket').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uezm2FpJAb9m"
      },
      "source": [
        "####**Does positive/negative sentiment towards a movie in the 'tags' dataset translate to high/low average rating?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owJ0d_NBAmGf"
      },
      "source": [
        "# Let's take a look at the tags data\n",
        "dataframes['tags'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SOnPgeZAx1K"
      },
      "source": [
        "# Our simplistic hypothesis here would be that we can define a set of positive and negative words. \n",
        "# If a \"tag\" contains a negative word, it conveys negative sentiment towards the movie\n",
        "# If a \"tag\" contains a positive word, it conveys positive sentiment towards the movie\n",
        "\n",
        "# Define a list of words:\n",
        "negative_words = [\"bad\", \"not\", \"terrible\", \"horrible\"]\n",
        "positive_words = [\"great\", \"good\", \"loved\", \"like\", \"fun\", \"funny\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAL0ckp80kro"
      },
      "source": [
        "# Define functions to determine whether a tag contains a positive or negative word\n",
        "def contains_negative_words(s):\n",
        "  for word in s.split():\n",
        "    if word in negative_words:\n",
        "      return True\n",
        "  return False \n",
        "\n",
        "def contains_positive_words(s):\n",
        "  for word in s.split():\n",
        "    if word in positive_words:\n",
        "      return True\n",
        "  return False \n",
        "\n",
        "# Creating new columns based on the functions\n",
        "dataframes['tags']['negative_sentiment'] = dataframes['tags']['tag'].apply(lambda x: contains_negative_words(x)) \n",
        "dataframes['tags']['positive_sentiment'] = dataframes['tags']['tag'].apply(lambda x: contains_positive_words(x)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIegE4CxBb9K"
      },
      "source": [
        "# Sample positive sentiment tags\n",
        "print(\"Positive sentiment\")\n",
        "print(dataframes['tags'][['tag', 'positive_sentiment']][dataframes['tags']['positive_sentiment']].head(), \"\\n\")\n",
        "\n",
        "# Sample negative sentiment tags\n",
        "print(\"Negative sentiment\")\n",
        "print(dataframes['tags'][['tag', 'negative_sentiment']][dataframes['tags']['negative_sentiment']].head(), \"\\n\")\n",
        "\n",
        "# Rows with positive AND negative sentiment\n",
        "print(\"Positive AND negative sentiment\")\n",
        "print(dataframes['tags']['tag'][(dataframes['tags']['positive_sentiment']) & (dataframes['tags']['negative_sentiment'])], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aROG8iZXCyXh"
      },
      "source": [
        "# let's mark confused rows appropriately\n",
        "# villain nonexistent or not needed for good story --> positive sentiment\n",
        "dataframes['tags'].iloc[2496, 4] = False\n",
        "dataframes['tags'].iloc[2496, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPbStI0oDy6O"
      },
      "source": [
        "# not funny --> negative sentiment\n",
        "dataframes['tags'].iloc[2563, 5] = False\n",
        "dataframes['tags'].iloc[2563, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgtwqC4uMkcH"
      },
      "source": [
        "# How many tags with positive/negative sentiment does the movie have?\n",
        "\n",
        "# Defining a dataset with positive tags only\n",
        "print(\"Movies with positive tags:\")\n",
        "positive_tags =  dataframes['tags'][dataframes['tags']['positive_sentiment']]\n",
        "# Grouping by movie and counting\n",
        "num_positive_tags = positive_tags.groupby(['movieId']).size()\n",
        "num_positive_tags = num_positive_tags.to_frame('num_positive_tags')\n",
        "print(num_positive_tags.head(), \"\\n\")\n",
        "\n",
        "\n",
        "# Defining a dataset with negative tags only\n",
        "print(\"Movies with negative tags:\")\n",
        "negative_tags =  dataframes['tags'][dataframes['tags']['negative_sentiment']]\n",
        "# Grouping by movie and counting\n",
        "num_negative_tags = negative_tags.groupby(['movieId']).size()\n",
        "num_negative_tags = num_negative_tags.to_frame('num_negative_tags')\n",
        "print(num_negative_tags.head(), \"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMqlvXVpQ2bp"
      },
      "source": [
        "# Left Join to add positive/negative sentiment to combined data\n",
        "dataframes['combined'] = dataframes['combined'].join(num_positive_tags, on='movieId',  how='left')\n",
        "dataframes['combined'] = dataframes['combined'].join(num_negative_tags, on='movieId',  how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "278WSMEZRbam"
      },
      "source": [
        "# Look at sample data\n",
        "cols = ['title', 'year', 'mean_rating', 'num_positive_tags', 'num_negative_tags']\n",
        "dataframes['combined'][cols][(dataframes['combined']['num_positive_tags'] > 0) | (dataframes['combined']['num_negative_tags'] > 0) ].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-8vRQ4vR6s4"
      },
      "source": [
        "# Fill NaN with 0\n",
        "dataframes['combined'] = dataframes['combined'].fillna(0)\n",
        "\n",
        "# Look at sample data again\n",
        "dataframes['combined'][cols][(dataframes['combined']['num_positive_tags'] > 0) | (dataframes['combined']['num_negative_tags'] > 0) ].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISOXP_jXLhpv"
      },
      "source": [
        "# If a move had positive sentiment, did it rate high?\n",
        "\n",
        "# take movies with positive tags and no negative tags\n",
        "positives = dataframes['combined'][(dataframes['combined']['num_positive_tags'] > 0) & (dataframes['combined']['num_negative_tags'] == 0)]\n",
        "positives['mean_rating'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27hHIKFVR_GZ"
      },
      "source": [
        "# if a movie had negative sentiment, did it rate low?\n",
        "\n",
        "# take movies with negative tags and no positive tags\n",
        "negatives = dataframes['combined'][(dataframes['combined']['num_negative_tags'] > 0) & (dataframes['combined']['num_positive_tags'] == 0)]\n",
        "negatives['mean_rating'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}